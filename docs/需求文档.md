# 智能客服问答系统需求文档

## 一、项目概述

### 1.1 项目背景
构建一个基于大语言模型（LLM）的智能客服问答系统，能够自动回答用户常见问题，提供7×24小时在线服务，降低人工客服成本。

### 1.2 项目目标
- 准确理解用户问题意图，准确率达到85%以上
- 从知识库中检索并返回相关答案
- 支持多轮对话，记住上下文信息
- 响应时间控制在3秒以内
- 支持知识库动态更新和管理

---

## 二、功能需求

### 2.1 核心功能

#### 2.1.1 智能问答
- **功能描述**：用户输入问题，系统返回准确答案
- **实现方式**：
  - 问题预处理（分词、去停用词、意图识别）
  - 向量化检索（使用Embedding模型）
  - 语义匹配（计算相似度）
  - LLM生成回答（结合检索结果）
- **输入**：用户文本问题
- **输出**：结构化答案（包含答案文本、置信度、来源）

#### 2.1.2 多轮对话
- **功能描述**：支持连续对话，保持上下文
- **实现方式**：
  - 会话管理（Session ID）
  - 上下文记忆（保留最近N轮对话）
  - 指代消解（理解"它"、"这个"等指代）
- **会话超时**：30分钟无交互自动清理

#### 2.1.3 知识库管理
- **功能描述**：管理员可以增删改查知识库内容
- **支持格式**：
  - FAQ问答对（JSON/CSV/Excel）
  - 文档导入（PDF/Word/Markdown）
  - 结构化数据（API对接）
- **核心操作**：
  - 添加/编辑/删除知识条目
  - 批量导入导出
  - 知识审核与发布
  - 向量索引自动更新

#### 2.1.4 意图识别与分类
- **功能描述**：识别用户问题类型
- **常见意图类型**：
  - 产品咨询
  - 售后服务
  - 订单查询
  - 投诉建议
  - 闲聊
- **路由策略**：根据意图类型选择不同处理流程

#### 2.1.5 相似问题推荐
- **功能描述**：当答案不确定时，推荐3-5个相似问题
- **触发条件**：匹配置信度低于阈值（如0.7）

#### 2.1.6 智能回退策略（三级回答机制）
- **功能描述**：根据问题类型自动选择最优回答方式
- **回答策略**：
  1. **知识库优先**：置信度 ≥ 20%，使用知识库内容回答
  2. **网络搜索补充**：置信度 < 20%，通过SearXNG进行网络搜索
  3. **通用AI兜底**：网络搜索无结果，使用LLM通用能力回答
- **优势**：确保任何问题都能得到合理回答，不再出现"无法回答"的情况

### 2.2 辅助功能

#### 2.2.1 敏感词过滤
- 识别并过滤违规内容
- 支持自定义敏感词库

#### 2.2.2 人工客服转接
- 当AI无法回答时，提示转人工
- 记录转接原因，用于优化知识库

#### 2.2.3 用户反馈收集
- 用户可对答案进行评价（满意/不满意）
- 收集反馈用于模型优化

#### 2.2.4 数据分析与监控
- 问题热点统计
- 回答准确率分析
- 系统性能监控（QPS、响应时间）
- 用户满意度报表

---

## 三、技术架构

### 3.1 整体架构图

```
┌─────────────────────────────────────────────────────────┐
│                        前端界面                          │
│         (Web页面 / 移动App / 企业微信集成)              │
└──────────────────────┬──────────────────────────────────┘
                       │ HTTP/WebSocket
┌──────────────────────┼──────────────────────────────────┐
│                  API网关层                               │
│              (FastAPI + 鉴权 + 限流)                     │
└──────────────────────┼──────────────────────────────────┘
                       │
┌──────────────────────┼──────────────────────────────────┐
│                  业务逻辑层                              │
├──────────────────────┼──────────────────────────────────┤
│  ┌────────────┐  ┌──────────┐  ┌─────────────┐        │
│  │ 对话管理   │  │ 意图识别 │  │ 答案生成    │        │
│  │   模块     │  │   模块   │  │   模块      │        │
│  └────────────┘  └──────────┘  └─────────────┘        │
└──────────────────────┼──────────────────────────────────┘
                       │
┌──────────────────────┼──────────────────────────────────┐
│                  数据处理层                              │
├──────────────────────┼──────────────────────────────────┤
│  ┌────────────┐  ┌──────────┐  ┌─────────────┐        │
│  │ Embedding  │  │ 向量检索 │  │  LLM调用    │        │
│  │   服务     │  │   服务   │  │   服务      │        │
│  └────────────┘  └──────────┘  └─────────────┘        │
└──────────────────────┼──────────────────────────────────┘
                       │
┌──────────────────────┴──────────────────────────────────┐
│                    数据存储层                            │
├─────────────────────────────────────────────────────────┤
│  ┌────────────┐  ┌──────────┐  ┌─────────────┐        │
│  │ 向量数据库 │  │ 关系数据库│  │  缓存层     │        │
│  │ (Milvus)  │  │(PostgreSQL)│ │  (Redis)    │        │
│  └────────────┘  └──────────┘  └─────────────┘        │
└─────────────────────────────────────────────────────────┘
```

### 3.2 技术选型

#### 3.2.1 后端技术栈
| 技术组件 | 选型方案 | 说明 |
|---------|---------|------|
| Web框架 | FastAPI | 异步高性能，自动生成API文档 |
| LLM框架 | LangChain | 简化LLM应用开发 |
| 语言模型 | Qwen3-8B (Ollama) | 本地部署，免费 |
| Embedding | nomic-embed-text (Ollama) | 文本向量化，768维，支持中英文 |
| 向量数据库 | Milvus | 语义检索，支持百万级向量 |
| 关系数据库 | PostgreSQL 16 | 知识库存储 |
| 缓存 | Redis 7 | 会话存储、热点缓存 |
| 网络搜索 | SearXNG | 开源元搜索引擎，用于知识库外问题 |
| 任务队列 | Celery | 异步任务处理 |

#### 3.2.2 前端技术栈
| 技术组件 | 选型方案 | 说明 |
|---------|---------|------|
| 前端框架 | Vue 3 | 渐进式JavaScript框架 |
| UI组件库 | Element Plus | Vue 3的企业级UI组件库 |
| 构建工具 | Vite | 下一代前端构建工具 |
| HTTP客户端 | Axios | Promise风格的HTTP库 |
| 路由管理 | Vue Router 4 | Vue官方路由管理器 |

#### 3.2.3 开发工具
- **版本管理**：Git
- **依赖管理**：Poetry / pip + requirements.txt
- **代码规范**：Black（格式化）+ Flake8（代码检查）
- **测试框架**：pytest + pytest-asyncio
- **API文档**：FastAPI自动生成Swagger文档
- **日志**：loguru
- **配置管理**：python-dotenv

#### 3.2.4 部署方案
- **容器化**：Docker + Docker Compose
- **Web服务器**：Uvicorn + Nginx
- **进程管理**：Supervisor / systemd
- **监控**：Prometheus + Grafana

---

## 四、数据模型设计

### 4.1 知识库表（knowledge_base）
| 字段名 | 类型 | 说明 |
|-------|------|------|
| id | INT | 主键 |
| question | TEXT | 标准问题 |
| answer | TEXT | 标准答案 |
| category | VARCHAR | 分类（产品/售后/订单等） |
| keywords | TEXT[] | 关键词数组 |
| embedding_vector | VECTOR | 向量表示 |
| created_at | TIMESTAMP | 创建时间 |
| updated_at | TIMESTAMP | 更新时间 |
| status | INT | 状态（0-草稿/1-已发布） |

### 4.2 对话历史表（conversation_history）
| 字段名 | 类型 | 说明 |
|-------|------|------|
| id | INT | 主键 |
| session_id | VARCHAR | 会话ID |
| user_id | VARCHAR | 用户ID |
| user_message | TEXT | 用户消息 |
| bot_response | TEXT | 机器人回复 |
| intent | VARCHAR | 识别的意图 |
| confidence | FLOAT | 置信度 |
| feedback | INT | 用户反馈（1-满意/0-不满意） |
| created_at | TIMESTAMP | 创建时间 |

### 4.3 用户反馈表（user_feedback）
| 字段名 | 类型 | 说明 |
|-------|------|------|
| id | INT | 主键 |
| conversation_id | INT | 对话ID（外键） |
| rating | INT | 评分（1-5） |
| feedback_text | TEXT | 反馈内容 |
| created_at | TIMESTAMP | 创建时间 |

---

## 五、接口设计

### 5.1 问答接口
```
POST /api/v1/chat
Content-Type: application/json

Request:
{
    "session_id": "uuid-string",
    "user_id": "user123",
    "message": "如何退货？",
    "context": []  // 可选：上下文信息
}

Response:
{
    "code": 200,
    "message": "success",
    "data": {
        "session_id": "uuid-string",
        "answer": "您可以在订单页面申请退货...",
        "confidence": 0.92,
        "intent": "售后服务",
        "related_questions": [
            "退货需要多久？",
            "退货运费谁承担？"
        ],
        "source": "knowledge_base_id_123"
    }
}
```

### 5.2 知识库管理接口
```
POST /api/v1/knowledge/add     - 添加知识条目
PUT /api/v1/knowledge/{id}     - 更新知识条目
DELETE /api/v1/knowledge/{id}  - 删除知识条目
GET /api/v1/knowledge/list     - 获取知识列表
POST /api/v1/knowledge/import  - 批量导入
```

### 5.3 反馈接口
```
POST /api/v1/feedback
Request:
{
    "conversation_id": 123,
    "rating": 5,
    "feedback_text": "回答很准确"
}
```

---

## 六、性能指标

### 6.1 响应性能
- 单次问答响应时间：< 3秒
- 系统并发处理能力：100 QPS
- 向量检索耗时：< 500ms

### 6.2 准确性指标
- 意图识别准确率：> 85%
- 答案匹配准确率：> 80%
- 用户满意度：> 75%

### 6.3 可用性指标
- 系统可用性：99.5%
- 知识库更新延迟：< 5分钟

---

## 七、实施计划

### ✅ Phase 1：基础框架搭建（已完成）
- [x] 项目初始化，搭建FastAPI框架
- [x] 数据库设计与搭建（PostgreSQL + Redis）
- [x] 基础API接口开发
- [x] Docker环境配置（含Milvus、SearXNG）

### ✅ Phase 2：核心功能开发（已完成）
- [x] Embedding服务集成（nomic-embed-text）
- [x] 向量数据库集成（Milvus）
- [x] LLM集成（Qwen3-8B via Ollama）
- [x] 问答核心逻辑实现
- [x] 知识库管理功能

### ✅ Phase 3：高级功能开发（已完成）
- [x] 多轮对话管理
- [x] 意图识别优化
- [x] 相似问题推荐
- [x] 智能回退策略（知识库→网络搜索→通用AI）
- [x] 网络搜索集成（SearXNG）

### ✅ Phase 4：前端开发（已完成）
- [x] Vue 3 + Element Plus 界面搭建
- [x] 智能问答聊天界面
- [x] 知识库管理界面
- [x] 答案来源标识展示

### 🔄 Phase 5：部署上线（进行中）
- [ ] 生产环境Dockerfile编写
- [ ] Docker Compose生产配置
- [ ] Nginx反向代理配置
- [ ] 监控告警配置
- [ ] 部署文档编写

---

## 八、风险与挑战

### 8.1 技术风险
- **LLM响应不稳定**：采用本地备用模型或重试机制
- **向量检索准确率不足**：优化Embedding模型，调整检索策略
- **高并发性能瓶颈**：引入负载均衡，增加缓存层

### 8.2 业务风险
- **知识库覆盖不全**：持续收集问题，补充知识库
- **用户问题表达多样**：训练意图识别模型，扩展同义词库
- **安全隐私问题**：敏感信息脱敏，用户数据加密存储

---

## 九、成本估算

### 9.1 开发成本
- 开发人员：1-2人 × 2-3个月
- 服务器资源：开发/测试/生产环境

### 9.2 运营成本
- LLM API调用费用（如使用OpenAI）：根据调用量预估
- 服务器费用：$100-300/月（根据规模）
- 向量数据库：开源方案免费 / 商业版按需
- 维护人员：1人

### 9.3 成本优化建议
- 优先使用开源模型（Qwen、ChatGLM）降低API费用
- 采用混合检索策略，减少不必要的LLM调用
- 使用缓存机制，相同问题直接返回缓存结果

---

## 十、后续扩展

### 10.1 功能扩展
- 多语言支持（中英文双语）
- 语音输入/输出
- 图片识别（OCR + 图像问答）
- 情感分析（识别用户情绪）

### 10.2 集成扩展
- 企业微信/钉钉机器人
- 在线客服系统集成
- CRM系统对接
- 工单系统联动

---

## 附录

### A. 参考资料
- LangChain官方文档：https://docs.langchain.com/
- FastAPI文档：https://fastapi.tiangolo.com/
- Milvus文档：https://milvus.io/docs/

### B. 开源项目参考
- QAnything（网易开源问答系统）
- Dify（LLM应用开发平台）
- ChatPDF（文档问答系统）

### C. 技术选型对比
详见：`docs/技术选型对比表.md`（待补充）

